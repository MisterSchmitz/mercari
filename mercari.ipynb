{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lzma\n",
    "import random\n",
    "import numpy as np\n",
    "import implicit\n",
    "from collections import defaultdict\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_mode = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if test_mode:\n",
    "    filename = \"train.tsv\"\n",
    "else:\n",
    "    filename = \"../input/unzipped/train.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allData = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(filename, encoding='utf8') as infile:\n",
    "    for row in infile:\n",
    "        allData.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove column labels\n",
    "column_labels = allData[0].split('\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allData = allData[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "data = []\n",
    "for row in allData:\n",
    "    arr = row.split('\\t')\n",
    "    features = []\n",
    "    features.append(float(arr[0]))  # train_id\n",
    "    features.append(arr[1])         # name\n",
    "    features.append(float(arr[2]))  # item_condition_id\n",
    "    features.append(arr[3])         # category_name (removing)\n",
    "    features.append(arr[4])         # brand_name\n",
    "    features.append(float(arr[5]))  # price\n",
    "    features.append(float(arr[6]))  # shipping\n",
    "    features.append(arr[7])         # item_description\n",
    "    data.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map each category to an index\n",
    "\"\"\"\n",
    "Format of categories:\n",
    "{0: '', 1: 'Women', 2: 'Men', 3: 'Beauty', 4: 'Kids'....\n",
    "\n",
    "\"\"\"\n",
    "(m0, m1, m2, m3, m4) = (0,0,0,0,0)\n",
    "categories = [set(),  set(),  set(),  set(),  set()]\n",
    "for row in data:\n",
    "    tmp = row[3].split('/')\n",
    "    for i in range(len(tmp)):\n",
    "        categories[i].add(tmp[i])\n",
    "categories = list(categories)\n",
    "for category in range(len(categories)):\n",
    "    s = {}\n",
    "    i = 0\n",
    "    for col in categories[category]:\n",
    "        s[col] = i\n",
    "        i += 1\n",
    "    categories[category] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create new dataset\n",
    "total_features = []\n",
    "total_labels = []\n",
    "for row in data:\n",
    "    tmp = row[3].split('/')\n",
    "    new_feature = []\n",
    "    # append item condition, shipping\n",
    "    new_feature += [row[2], row[6]]\n",
    "    # append categorical ids\n",
    "    for category in range(5):\n",
    "        if category >= len(tmp):\n",
    "            new_feature.append(-1)\n",
    "        else:\n",
    "            new_feature.append(categories[category][tmp[category]])\n",
    "    # append new features\n",
    "    total_features.append(new_feature)\n",
    "    # append labels\n",
    "    total_labels.append(row[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features = total_features[len(total_features)//2:]\n",
    "train_labels = total_labels[len(total_labels)//2:]\n",
    "\n",
    "valid_features = total_features[len(total_features)//2:]\n",
    "valid_labels = total_labels[len(total_labels)//2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingRegressor(n_estimators=100)\n",
    "clf = clf.fit(valid_features, valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7209151674227384\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "predictions = clf.predict(valid_features)\n",
    "rmsle = 0\n",
    "bad = 0\n",
    "for i in range(len(predictions)):\n",
    "    if predictions[i]+1 < 0:\n",
    "        predictions[i] = 0.0\n",
    "        bad += 1\n",
    "    rmsle += (math.log(predictions[i]+1.0) - math.log(valid_labels[i]+1.0)) ** 2\n",
    "rmsle /= len(predictions)\n",
    "print(math.sqrt(rmsle))\n",
    "print(bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = GradientBoostingRegressor(n_estimators=100)\n",
    "clf = clf.fit(total_features, total_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if test_mode:\n",
    "    filename = \"test.tsv\"\n",
    "else:\n",
    "    filename = \"../input/unzipped/test.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allTestData = []\n",
    "with open(filename, encoding='utf8') as infile:\n",
    "    for row in infile:\n",
    "        allTestData.append(row)\n",
    "# remove column labels\n",
    "column_labels = allTestData[0].split('\\t')\n",
    "allTestData = allTestData[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "testData = []\n",
    "for row in allTestData:\n",
    "    arr = row.split('\\t')\n",
    "    features = []\n",
    "    features.append(float(arr[0]))  # train_id\n",
    "    features.append(arr[1])         # name\n",
    "    features.append(float(arr[2]))  # item_condition_id\n",
    "    features.append(arr[3])         # category_name (removing)\n",
    "    features.append(arr[4])         # brand_name\n",
    "#     features.append(float(arr[5]))  # price\n",
    "    features.append(float(arr[5]))  # shipping\n",
    "    features.append(arr[6])         # item_description\n",
    "    testData.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(m0, m1, m2, m3, m4) = (0,0,0,0,0)\n",
    "categories = [set(),  set(),  set(),  set(),  set()]\n",
    "for row in testData:\n",
    "    tmp = row[3].split('/')\n",
    "    for i in range(len(tmp)):\n",
    "        categories[i].add(tmp[i])\n",
    "categories = list(categories)\n",
    "for category in range(len(categories)):\n",
    "    s = {}\n",
    "    i = 0\n",
    "    for col in categories[category]:\n",
    "        s[col] = i\n",
    "        i += 1\n",
    "    categories[category] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get test features and labels\n",
    "test_features = []\n",
    "for row in testData:\n",
    "    tmp = row[3].split('/')\n",
    "    new_feature = []\n",
    "    # append item condition, shipping\n",
    "    new_feature += [row[2], row[5]]\n",
    "    # append categorical ids\n",
    "    for category in range(5):\n",
    "        if category >= len(tmp):\n",
    "            new_feature.append(-1)\n",
    "        else:\n",
    "            new_feature.append(categories[category][tmp[category]])\n",
    "    # append new features\n",
    "    test_features.append(new_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = clf.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 27.6127500819\n",
      "1 19.427225325\n",
      "2 29.1532813925\n",
      "3 26.414523083\n",
      "4 19.2845774181\n",
      "5 13.310701571\n",
      "6 28.8131201961\n",
      "7 27.045861298\n",
      "8 26.4258121404\n",
      "9 16.0596094374\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    testid = int(testData[i][0])\n",
    "    pred = predictions[i]\n",
    "    print(testid, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sample_submission.csv\", 'w') as predictions_file:\n",
    "    predictions_file.write(\"test_id,price\")\n",
    "    for i in range(len(testData)):\n",
    "        testid = int(testData[i][0])\n",
    "        pred = predictions[i]\n",
    "        output = str(testid)+\",\"+str(pred)+\"\\n\"\n",
    "        predictions_file.write(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
